{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model N-Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the tagalog POS dataset\n",
    "tl_pos_data = pd.read_json('src/json data/tl_pos.json')\n",
    "il_pos_data = pd.read_json('src/json data/il_pos.json')\n",
    "\n",
    "tl_pos_sen_list = tl_pos_data['POS']\n",
    "il_pos_sen_list = il_pos_data['POS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the needed Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_unigram_list = []\n",
    "tl_unigram_count_sen = []\n",
    "tl_unigram_len = []\n",
    "il_unigram_list = []\n",
    "il_unigram_count_sen = []\n",
    "il_unigram_len = []\n",
    "\n",
    "tl_bigram_list = []\n",
    "tl_bigram_count_sen = []\n",
    "tl_bigram_len = []\n",
    "il_bigram_list = []\n",
    "il_bigram_count_sen = []\n",
    "il_bigram_len = []\n",
    "\n",
    "tl_trigram_list=[]\n",
    "tl_trigram_count_sen=[]\n",
    "tl_trigram_len = []\n",
    "il_trigram_list=[]\n",
    "il_trigram_count_sen=[]\n",
    "il_trigram_len = []\n",
    "\n",
    "tl_fourgram_list=[]\n",
    "tl_fourgram_count_sen=[]\n",
    "tl_fourgram_len = []\n",
    "il_fourgram_list=[]\n",
    "il_fourgram_count_sen=[]\n",
    "il_fourgram_len = []\n",
    "\n",
    "tl_ngram_list = []\n",
    "il_ngram_list = []\n",
    "\n",
    "tl_notencap_list = []\n",
    "il_notencap_list = []\n",
    "tl_notencap_count_sen = []\n",
    "il_notencap_count_sen = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nGram Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nGram(text, n):\n",
    "    \n",
    "    ngrams=[]\n",
    "    #collect n-gram\n",
    "    for i in range(len(text)-n+1): # i is the index of the first word of the n-gram\n",
    "        temp=[text[j] for j in range(i, i+n)] # j is the index of the word in the n-gram\n",
    "        ngrams.append(\" \".join(temp))\n",
    "        \n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulating Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encapsulate(pos_sen_list, fourgram_list, trigram_list, bigram_list, unigram_list, ngram_list, notencap_list,fourgram_count_sen, trigram_count_sen, bigram_count_sen, unigram_count_sen, notencap_count_sen):\n",
    "  for pos_sen in pos_sen_list: # loop for going through all the POS sentence structures\n",
    "    unigram = []\n",
    "    bigram = []\n",
    "    trigram = []\n",
    "    fourgram = []\n",
    "    ngram = []\n",
    "    notencap = []\n",
    "    \n",
    "    unigram_count = 0\n",
    "    bigram_count = 0\n",
    "    trigram_count=0\n",
    "    fourgram_count=0\n",
    "    notencap_count = 0\n",
    "\n",
    "    pos_index = 0\n",
    "    curr_pos = 0\n",
    "    next_pos = \"\"\n",
    "    next2_pos= \"\"\n",
    "    next3_pos= \"\"\n",
    "    \n",
    "    \n",
    "    for pos in pos_sen: # loop for all the POS in a sentence\n",
    "      if pos_index != curr_pos and pos_index != 0:\n",
    "        pass\n",
    "      \n",
    "      else:\n",
    "        if pos_index < (len(pos_sen) - 1):\n",
    "          next_pos = pos_sen[pos_index+1]\n",
    "        \n",
    "        if pos_index < (len(pos_sen) - 2):\n",
    "          next2_pos = pos_sen[pos_index + 2]\n",
    "            \n",
    "        if pos_index < (len(pos_sen) - 3):\n",
    "          next3_pos = pos_sen[pos_index + 3]\n",
    "        \n",
    "        # FOURGRAMS\n",
    "        if pos == 'VB' and next_pos == 'DT'  and next2_pos == 'JJ' and next3_pos == 'NN':\n",
    "          fourgram.extend([[pos, next_pos, next2_pos, next3_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos, next3_pos]])\n",
    "          fourgram_count += 1\n",
    "          curr_pos = pos_index + 4\n",
    "\n",
    "        elif pos == 'NN' and next_pos == 'DT'  and next2_pos == 'JJ' and next3_pos == 'VB':\n",
    "          fourgram.extend([[pos, next_pos, next2_pos, next3_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos, next3_pos]])\n",
    "          fourgram_count += 1\n",
    "          curr_pos = pos_index + 4\n",
    "          \n",
    "        elif pos == 'JJ' and next_pos == 'NN'  and next2_pos == 'RB' and next3_pos == 'VB':\n",
    "          fourgram.extend([[pos, next_pos, next2_pos, next3_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos, next3_pos]])\n",
    "          fourgram_count += 1\n",
    "          curr_pos = pos_index + 4\n",
    "          \n",
    "        elif pos == 'DT' and next_pos == 'NN'  and next2_pos == 'DT' and next3_pos == 'VB':\n",
    "          fourgram.extend([[pos, next_pos, next2_pos, next3_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos, next3_pos]])\n",
    "          fourgram_count += 1\n",
    "          curr_pos = pos_index + 4\n",
    "          \n",
    "        elif pos == 'DT' and next_pos == 'VB'  and next2_pos == 'DT' and next3_pos == 'NN':\n",
    "          fourgram.extend([[pos, next_pos, next2_pos, next3_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos, next3_pos]])\n",
    "          fourgram_count += 1\n",
    "          curr_pos = pos_index + 4\n",
    "          \n",
    "        elif pos == 'DT' and next_pos == 'NN'  and next2_pos == 'DT' and next3_pos == 'JJ':\n",
    "          fourgram.extend([[pos, next_pos, next2_pos, next3_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos, next3_pos]])\n",
    "          fourgram_count += 1\n",
    "          curr_pos = pos_index + 4\n",
    "        \n",
    "        elif pos == 'DT' and next_pos == 'JJ'  and next2_pos == 'DT' and next3_pos == 'NN':\n",
    "          fourgram.extend([[pos, next_pos, next2_pos, next3_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos, next3_pos]])\n",
    "          fourgram_count += 1\n",
    "          curr_pos = pos_index + 4\n",
    "          \n",
    "        # TRIGRAMS\n",
    "        elif pos == 'VB' and next_pos == 'DT'  and next2_pos == 'NN':\n",
    "          trigram.extend([[pos, next_pos, next2_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos]])\n",
    "          trigram_count += 1\n",
    "          curr_pos = pos_index + 3\n",
    "\n",
    "        elif pos == 'RB' and next_pos == 'DT'  and next2_pos == 'VB':\n",
    "          trigram.extend([[pos, next_pos, next2_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos]])\n",
    "          trigram_count += 1\n",
    "          curr_pos = pos_index + 3\n",
    "          \n",
    "        elif pos == 'DT' and next_pos == 'JJ'  and next2_pos == 'NN':\n",
    "          trigram.extend([[pos, next_pos, next2_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos]])\n",
    "          trigram_count += 1\n",
    "          curr_pos = pos_index + 3\n",
    "          \n",
    "        elif pos == 'DT' and next_pos == 'NN'  and next2_pos == 'VB': # from IL\n",
    "          trigram.extend([[pos, next_pos, next2_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos]])\n",
    "          trigram_count += 1\n",
    "          curr_pos = pos_index + 3\n",
    "        \n",
    "        elif pos == 'DT' and next_pos == 'NN'  and next2_pos == 'JJ': # from IL\n",
    "          trigram.extend([[pos, next_pos, next2_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos]])\n",
    "          trigram_count += 1\n",
    "          curr_pos = pos_index + 3\n",
    "          \n",
    "        elif pos == 'VB' and next_pos == 'DT'  and next2_pos == 'JJ':\n",
    "          trigram.extend([[pos, next_pos, next2_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos]])\n",
    "          trigram_count += 1\n",
    "          curr_pos = pos_index + 3 \n",
    "          \n",
    "        elif pos == 'JJ' and next_pos == 'DT'  and next2_pos == 'VB':\n",
    "          trigram.extend([[pos, next_pos, next2_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos]])\n",
    "          trigram_count += 1\n",
    "          curr_pos = pos_index + 3 \n",
    "        \n",
    "        elif pos == 'RB' and next_pos == 'DT'  and next2_pos == 'JJ':\n",
    "          trigram.extend([[pos, next_pos, next2_pos]])\n",
    "          ngram.extend([[pos, next_pos, next2_pos]])\n",
    "          trigram_count += 1\n",
    "          curr_pos = pos_index + 3\n",
    "\n",
    "        # BIGRAMS\n",
    "        elif len(pos_sen) == 2:\n",
    "          bigram.extend([[pos, next_pos]])\n",
    "          ngram.extend([[pos, next_pos]])\n",
    "          bigram_count += 1\n",
    "          curr_pos = pos_index + 2\n",
    "\n",
    "        elif pos == 'DT' and next_pos == 'NN':\n",
    "          bigram.extend([[pos, next_pos]])\n",
    "          ngram.extend([[pos, next_pos]])\n",
    "          bigram_count += 1\n",
    "          curr_pos = pos_index + 2\n",
    "        \n",
    "        elif pos == 'VB' and next_pos == 'NN':\n",
    "          bigram.extend([[pos, next_pos]])\n",
    "          ngram.extend([[pos, next_pos]])\n",
    "          bigram_count += 1\n",
    "          curr_pos = pos_index + 2\n",
    "\n",
    "        elif pos == 'JJ' and next_pos == 'NN':\n",
    "          bigram.extend([[pos, next_pos]])\n",
    "          ngram.extend([[pos, next_pos]])\n",
    "          bigram_count += 1\n",
    "          curr_pos = pos_index + 2\n",
    "          \n",
    "        elif pos == 'NN' and next_pos == 'VB':\n",
    "          bigram.extend([[pos, next_pos]])\n",
    "          ngram.extend([[pos, next_pos]])\n",
    "          bigram_count += 1\n",
    "          curr_pos = pos_index + 2\n",
    "\n",
    "        # UNIGRAMS\n",
    "        elif pos == 'CC' or pos == 'SW':\n",
    "          unigram.append([pos])\n",
    "          ngram.append([pos])\n",
    "          unigram_count += 1\n",
    "          curr_pos = pos_index + 1\n",
    "          \n",
    "        else:\n",
    "          notencap.append([pos])\n",
    "          # ngram.append([pos])\n",
    "          # notencap_count += 1\n",
    "          curr_pos = pos_index + 1\n",
    "          \n",
    "          \n",
    "      pos_index += 1\n",
    "    \n",
    "    fourgram_list.append(fourgram)\n",
    "    trigram_list.append(trigram)\n",
    "    bigram_list.append(bigram)\n",
    "    unigram_list.append(unigram)\n",
    "    ngram_list.append(ngram)\n",
    "    notencap_list.append(notencap)\n",
    "    \n",
    "    fourgram_count_sen.append(fourgram_count) \n",
    "    trigram_count_sen.append(trigram_count)\n",
    "    bigram_count_sen.append(bigram_count)\n",
    "    unigram_count_sen.append(unigram_count)\n",
    "    # notencap_count_sen.append(notencap_count)\n",
    "    \n",
    "    fourgram_count_list = np.array(fourgram_count_sen)\n",
    "    trigram_count_list = np.array(trigram_count_sen)\n",
    "    bigram_count_list = np.array(bigram_count_sen)\n",
    "    unigram_count_list = np.array(unigram_count_sen)\n",
    "    # notencap_count_list = np.array(notencap_count_sen)\n",
    "\n",
    "    ngram_count = fourgram_count_list + trigram_count_list + bigram_count_list + unigram_count_list\n",
    "  return ngram_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_ngram_count_list = encapsulate(tl_pos_sen_list, tl_fourgram_list, tl_trigram_list, tl_bigram_list, tl_unigram_list, tl_ngram_list, tl_notencap_list, tl_fourgram_count_sen, tl_trigram_count_sen, tl_bigram_count_sen, tl_unigram_count_sen, tl_notencap_count_sen)\n",
    "il_ngram_count_list = encapsulate(il_pos_sen_list, il_fourgram_list, il_trigram_list, il_bigram_list, il_unigram_list, il_ngram_list, il_notencap_list, il_fourgram_count_sen, il_trigram_count_sen, il_bigram_count_sen, il_unigram_count_sen, il_notencap_count_sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing in Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tl_ngram = pd.DataFrame(columns=['Tagalog POS Struct', 'Tagalog 4-Gram', 'Tagalog Trigram', 'Tagalog Bigram', 'Tagalog Unigram', 'Tagalog nGram', 'Tagalog N-Gram Count'])\n",
    "dict_tl_ngram['Tagalog POS Struct']= tl_pos_sen_list\n",
    "dict_tl_ngram['Tagalog 4-Gram']= tl_fourgram_list\n",
    "dict_tl_ngram['Tagalog Trigram']= tl_trigram_list\n",
    "dict_tl_ngram['Tagalog Bigram']= tl_bigram_list\n",
    "dict_tl_ngram['Tagalog Unigram']= tl_unigram_list\n",
    "dict_tl_ngram['Tagalog nGram']= tl_ngram_list\n",
    "dict_tl_ngram['Tagalog N-Gram Count']= tl_ngram_count_list\n",
    "dict_tl_ngram['Tagalog Not Encapsulated']= tl_notencap_list\n",
    "\n",
    "dict_il_ngram = pd.DataFrame(columns=['Ilokano POS Struct', 'Ilokano 4-Gram', 'Ilokano Trigram', 'Ilokano Bigram', 'Ilokano Unigram', 'Ilokano nGram', 'Ilokano N-Gram Count' ])\n",
    "dict_il_ngram['Ilokano POS Struct']= il_pos_sen_list\n",
    "dict_il_ngram['Ilokano 4-Gram']= il_fourgram_list\n",
    "dict_il_ngram['Ilokano Trigram']= il_trigram_list\n",
    "dict_il_ngram['Ilokano Bigram']= il_bigram_list\n",
    "dict_il_ngram['Ilokano Unigram']= il_unigram_list\n",
    "dict_il_ngram['Ilokano nGram']= il_ngram_list\n",
    "dict_il_ngram['Ilokano N-Gram Count']= il_ngram_count_list\n",
    "dict_il_ngram['Ilokano Not Encapsulated']= il_notencap_list\n",
    "\n",
    "dict_compare = pd.DataFrame(columns=['Tagalog N-Gram counter', 'Ilokano N-Gram counter'])\n",
    "dict_compare['Tagalog N-Gram counter'] = dict_tl_ngram['Tagalog N-Gram Count']\n",
    "dict_compare['Ilokano N-Gram counter'] = dict_il_ngram['Ilokano N-Gram Count']\n",
    "dict_compare['Tagalog nGram'] = dict_tl_ngram['Tagalog nGram']\n",
    "dict_compare['Ilokano nGram'] = dict_il_ngram['Ilokano nGram']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the head of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tl_ngram.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_il_ngram.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_compare.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the dictionary to a JSON File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Tagalog N-Gram data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dict_tl_ngram_rec = dict_tl_ngram.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open('src/json data/Example-Based/Language Model/dict_tl_ngram.json', 'w') as outfile:\n",
    "        json.dump(dict_tl_ngram_rec, outfile)\n",
    "    print('Successfully saved Tagalog N-Gram data to JSON file!')\n",
    "except:\n",
    "    print('Error saving Tagalog N-Gram data to JSON file!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Ilokano N-Gram data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_il_ngram_rec = dict_il_ngram.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open('src/json data/Example-Based/Language Model/dict_il_ngram.json', 'w') as outfile:\n",
    "        json.dump(dict_il_ngram_rec, outfile)\n",
    "    print('Successfully saved Ilokano N-Gram data to JSON file!')\n",
    "except:\n",
    "    print('Error saving Ilokano N-Gram data to JSON file!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd5e40cb983109c15fc1053f6f3e661cc97e68e07c1758cdbd2441c60186ce19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
