{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example-Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of the Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Tagalog Part of Speech Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the tagalog POS dataset\n",
    "il_pos_data = pd.read_json('../../src/json data/Ilokano to Tagalog/il_pos.json')\n",
    "\n",
    "il_doc_len = len(il_pos_data)\n",
    "\n",
    "print('Number of documents in the dataset: {}'.format(il_doc_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Ilokano Part of Speech Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the tagalog POS dataset\n",
    "tl_pos_data = pd.read_json('../../src/json data/Tagalog to Ilokano/tl_pos.json')\n",
    "\n",
    "tl_doc_len = len(tl_pos_data)\n",
    "\n",
    "tl_pos_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Tagalog Part of Speech Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sen_poss = pd.DataFrame(il_pos_data['POS'])\n",
    "\n",
    "dict_sen_poss.columns = ['Ilokano POS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Ilokano Part of Speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sen_poss['Tagalog POS'] = tl_pos_data['POS']\n",
    "\n",
    "dict_sen_poss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagalog to Ilokano Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_sen_poss_list = dict_sen_poss['Tagalog POS']\n",
    "il_sen_poss_list = dict_sen_poss['Ilokano POS']\n",
    "\"\"\"\n",
    "putting the POS of the sentences in a list object\n",
    "\"\"\"\n",
    "\n",
    "dict_il_tl_sw = pd.DataFrame(columns=['Ilokano Single Words', 'Tagalog Single Words'])\n",
    "dict_il_tl_vb = pd.DataFrame(columns=['Ilokano Verb', 'Tagalog Verb'])\n",
    "dict_il_tl_nn = pd.DataFrame(columns=['Ilokano Noun', 'Tagalog Noun'])\n",
    "dict_il_tl_jj = pd.DataFrame(columns=['Ilokano Adjective', 'Tagalog Adjective'])\n",
    "dict_il_tl_rb = pd.DataFrame(columns=['Ilokano Adverb', 'Tagalog Adverb'])\n",
    "dict_il_tl_cc = pd.DataFrame(columns=['Ilokano Conjunction', 'Tagalog Conjunction'])\n",
    "dict_il_tl_pr = pd.DataFrame(columns=['Ilokano Preposition', 'Tagalog Preposition'])\n",
    "dict_il_tl_dt = pd.DataFrame(columns=['Ilokano Determiner', 'Tagalog Determiner'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending in the List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Verb List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_vb_list(il_verb, il_verb_list, tl_verb, tl_verb_list, curr_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_verb_count_list, tl_verb_count, il_verb_count_list, il_verb_count, il_verb_term_count, il_verb_sen, il_verb_count_list_tf, il_sen_len, tl_verb_sen, tl_verb_count_list_idf, tl_verb_count_list_tf, tl_verb_count_tf, tl_sen_len):\n",
    "    \n",
    "    if il_verb not in il_verb_list: # il_verb_list = json ftle of verbs\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        il_verb_list.append(il_verb)\n",
    "        il_verb_count.append(1) \n",
    "        il_verb_term_count.append(il_verb_count) # not necessary\n",
    "        \n",
    "        if il_verb not in il_verb_sen: # il_verb_sen - list of verbs in a single sentence\n",
    "            il_verb_sen.append(il_verb)\n",
    "            il_verb_count_list.append(1)\n",
    "            il_verb_count_list_tf.append([1/il_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = il_verb_list.index(il_verb)\n",
    "        \n",
    "        temp_verb_index = il_verb_list[temp_index].index(il_verb[0]) # not necessary\n",
    "        il_verb_term_count[temp_index][temp_verb_index] += 1\n",
    "\n",
    "        if il_verb not in il_verb_sen:\n",
    "            il_verb_sen.append(il_verb)\n",
    "            il_verb_count_list[temp_index] += 1\n",
    "            il_verb_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                il_verb_count_list_tf[temp_index][sp_index] += (1/il_sen_len)\n",
    "            except:\n",
    "                il_verb_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_tl_pos == 'VB' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if VB : VB\n",
    "        if the tlokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and next_tl_pos == 'VB' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if VB : DT VB\n",
    "        if the tlokano POS is a determiner and the next POS is a verb\n",
    "        eg. Ntlalang : ti Aramid\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index)\n",
    "        matched.append(wp_index + 1) \n",
    "\n",
    "    elif curr_tl_pos == 'NN' and next_tl_pos == 'VB' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if VB : NN VB\n",
    "        if the tlokano POS is a determiner and the next POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index + 1)\n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and next_tl_pos == 'NN' and next2_tl_pos == 'VB' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if VB DT NN : DT NN VB\n",
    "        if the tlokano POS is a determiner and the next POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index + 2]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index + 2)\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if VB : Other POS\n",
    "        if the tlokano POS is not a verb\n",
    "        \"\"\"\n",
    "        tl_verb.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        tl_verb_list.append(tl_verb)\n",
    "        if tl_verb[0] == 'None':\n",
    "            tl_verb_count.append(0)\n",
    "            tl_verb_count_tf.append(round((0/tl_sen_len), 6))\n",
    "        else:\n",
    "            tl_verb_count.append(1)\n",
    "            tl_verb_count_tf.append(round((1/tl_sen_len), 6))\n",
    "        tl_verb_count_list.append(tl_verb_count)\n",
    "        tl_verb_count_list_tf.append(tl_verb_count_tf)\n",
    "        \n",
    "        if tl_verb[0] not in tl_verb_sen:\n",
    "            tl_verb_sen.append(tl_verb[0])\n",
    "            if tl_verb[0] == 'None':\n",
    "                tl_verb_count_list_idf.append([0])\n",
    "            else:\n",
    "                tl_verb_count_list_idf.append([1])\n",
    "        else:\n",
    "            tl_verb_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if tl_verb[0] not in tl_verb_list[temp_index]:\n",
    "            tl_verb_list[temp_index].append(tl_verb[0]) # temp_index = row index of the verb\n",
    "            if tl_verb[0] == 'None':\n",
    "                tl_verb_count_list[temp_index].append(0)\n",
    "                tl_verb_count_list_tf[temp_index].append(round((0/tl_sen_len), 6))\n",
    "            else:\n",
    "                tl_verb_count_list[temp_index].append(1)\n",
    "                tl_verb_count_list_tf[temp_index].append(round((1/tl_sen_len), 6)) \n",
    "            \n",
    "            if tl_verb[0] not in tl_verb_sen: # tl_verb_sen = list of verbs in  a single sentence\n",
    "                tl_verb_sen.append(tl_verb[0])\n",
    "                if tl_verb[0] == 'None':\n",
    "                    tl_verb_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    tl_verb_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                tl_verb_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the verb is already in tl_verb_list\n",
    "            temp_verb_index = tl_verb_list[temp_index].index(tl_verb[0])\n",
    "            if tl_verb[0] == 'None':\n",
    "                tl_verb_count_list[temp_index][temp_verb_index] += 0\n",
    "                tl_verb_count_list_tf[temp_index][temp_verb_index] += (0/tl_sen_len)\n",
    "            else:\n",
    "                tl_verb_count_list[temp_index][temp_verb_index] += 1\n",
    "                tl_verb_count_list_tf[temp_index][temp_verb_index] += (1/tl_sen_len)\n",
    "            tl_verb_count_list_tf[temp_index][temp_verb_index] = round(tl_verb_count_list_tf[temp_index][temp_verb_index], 6)\n",
    "            \n",
    "            if tl_verb[0] not in tl_verb_sen:\n",
    "                tl_verb_sen.append(tl_verb[0])\n",
    "                if tl_verb[0] == 'None':\n",
    "                    tl_verb_count_list_idf[temp_index][temp_verb_index] += 0\n",
    "                else:\n",
    "                    tl_verb_count_list_idf[temp_index][temp_verb_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Noun List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_nn_list(il_noun, il_noun_list, tl_noun, tl_noun_list, curr_tl_pos, next_tl_pos, matched, sp_index, wp_index, tl_noun_count_list, tl_noun_count, il_noun_count_list, il_noun_count, il_noun_term_count, il_noun_sen, il_noun_count_list_tf, il_sen_len, tl_noun_sen, tl_noun_count_list_idf, tl_noun_count_list_tf, tl_noun_count_tf, tl_sen_len):\n",
    "    \n",
    "    if il_noun not in il_noun_list:\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        il_noun_list.append(il_noun)\n",
    "        il_noun_count.append(1) \n",
    "        il_noun_term_count.append(il_noun_count)\n",
    "        \n",
    "        if il_noun not in il_noun_sen:\n",
    "            il_noun_sen.append(il_noun)\n",
    "            il_noun_count_list.append(1)\n",
    "            il_noun_count_list_tf.append([1/il_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = il_noun_list.index(il_noun)\n",
    "\n",
    "        temp_noun_index = il_noun_list[temp_index].index(il_noun[0])\n",
    "        il_noun_term_count[temp_index][temp_noun_index] += 1\n",
    "        \n",
    "        if il_noun not in il_noun_sen:\n",
    "            il_noun_sen.append(il_noun)\n",
    "            il_noun_count_list[temp_index] += 1\n",
    "            il_noun_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                il_noun_count_list_tf[temp_index][sp_index] += (1/il_sen_len)\n",
    "            except:\n",
    "                il_noun_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the noun in the tagalog noun\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_tl_pos == 'NN':\n",
    "        \"\"\"\n",
    "        if NN : NN\n",
    "        if the tlokano POS is a noun\n",
    "        \"\"\"\n",
    "        temp_noun = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_noun.append(temp_noun)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and next_tl_pos == 'NN':    \n",
    "        \"\"\"\n",
    "        if NN : DT NN\n",
    "        if the tlokano POS is a determiner and the next POS is a noun\n",
    "        \"\"\"\n",
    "        temp_next_noun = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_noun.append(temp_next_noun) \n",
    "        matched.append(wp_index + 1)\n",
    "          \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if NN : Other POS\n",
    "        if the tlokano POS is not a noun\n",
    "        \"\"\"\n",
    "        tl_noun.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        tl_noun_list.append(tl_noun)\n",
    "        if tl_noun[0] == 'None':\n",
    "            tl_noun_count.append(0)\n",
    "            tl_noun_count_tf.append(round((0/tl_sen_len), 6))\n",
    "        else:\n",
    "            tl_noun_count.append(1)\n",
    "            tl_noun_count_tf.append(round((1/tl_sen_len), 6))\n",
    "        tl_noun_count_list.append(tl_noun_count)\n",
    "        tl_noun_count_list_tf.append(tl_noun_count_tf)\n",
    "        \n",
    "        if tl_noun[0] not in tl_noun_sen:\n",
    "            tl_noun_sen.append(tl_noun[0])\n",
    "            if tl_noun[0] == 'None':\n",
    "                tl_noun_count_list_idf.append([0])\n",
    "            else:\n",
    "                tl_noun_count_list_idf.append([1])\n",
    "        else:\n",
    "            tl_noun_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if tl_noun[0] not in tl_noun_list[temp_index]:\n",
    "            tl_noun_list[temp_index].append(tl_noun[0]) # temp_index = row index of the noun\n",
    "            if tl_noun[0] == 'None':\n",
    "                tl_noun_count_list[temp_index].append(0)\n",
    "                tl_noun_count_list_tf[temp_index].append(round((0/tl_sen_len), 6))\n",
    "            else:\n",
    "                tl_noun_count_list[temp_index].append(1)\n",
    "                tl_noun_count_list_tf[temp_index].append(round((1/tl_sen_len), 6)) \n",
    "            \n",
    "            if tl_noun[0] not in tl_noun_sen: # tl_noun_sen = list of nouns in  a single sentence\n",
    "                tl_noun_sen.append(tl_noun[0])\n",
    "                if tl_noun[0] == 'None':\n",
    "                    tl_noun_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    tl_noun_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                tl_noun_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the noun is already in tl_noun_list\n",
    "            temp_noun_index = tl_noun_list[temp_index].index(tl_noun[0])\n",
    "            if tl_noun[0] == 'None':\n",
    "                tl_noun_count_list[temp_index][temp_noun_index] += 0\n",
    "                tl_noun_count_list_tf[temp_index][temp_noun_index] += (0/tl_sen_len)\n",
    "            else:\n",
    "                tl_noun_count_list[temp_index][temp_noun_index] += 1\n",
    "                tl_noun_count_list_tf[temp_index][temp_noun_index] += (1/tl_sen_len)\n",
    "            tl_noun_count_list_tf[temp_index][temp_noun_index] = round(tl_noun_count_list_tf[temp_index][temp_noun_index], 6)\n",
    "            \n",
    "            if tl_noun[0] not in tl_noun_sen:\n",
    "                tl_noun_sen.append(tl_noun[0])\n",
    "                if tl_noun[0] == 'None':\n",
    "                    tl_noun_count_list_idf[temp_index][temp_noun_index] += 0\n",
    "                else:\n",
    "                    tl_noun_count_list_idf[temp_index][temp_noun_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Adjective List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_jj_list(il_adj, il_adj_list, tl_adj, tl_adj_list, curr_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_adj_count_list, tl_adj_count, il_adj_count_list, il_adj_count, il_adj_term_count, il_adj_sen, il_adj_count_list_tf, il_sen_len, tl_adj_sen, tl_adj_count_list_idf, tl_adj_count_list_tf, tl_adj_count_tf, tl_sen_len):\n",
    "    \n",
    "    if il_adj not in il_adj_list:\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        il_adj_list.append(il_adj)\n",
    "        il_adj_count.append(1) \n",
    "        il_adj_term_count.append(il_adj_count)\n",
    "        \n",
    "        if il_adj not in il_adj_sen:\n",
    "            il_adj_sen.append(il_adj)\n",
    "            il_adj_count_list.append(1)\n",
    "            il_adj_count_list_tf.append([1/il_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = il_adj_list.index(il_adj)\n",
    "\n",
    "        temp_adj_index = il_adj_list[temp_index].index(il_adj[0])\n",
    "        il_adj_term_count[temp_index][temp_adj_index] += 1\n",
    "        \n",
    "        if il_adj not in il_adj_sen:\n",
    "            il_adj_sen.append(il_adj)\n",
    "            il_adj_count_list[temp_index] += 1\n",
    "            il_adj_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                il_adj_count_list_tf[temp_index][sp_index] += (1/il_sen_len)\n",
    "            except:\n",
    "                il_adj_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the adj in the tagalog adj\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_tl_pos == 'JJ':\n",
    "        \"\"\"\n",
    "        if JJ : JJ\n",
    "        if the tlokano POS is an adj\n",
    "        \"\"\"\n",
    "        temp_adj = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_adj.append(temp_adj)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and next_tl_pos == 'JJ':    \n",
    "        \"\"\"\n",
    "        if JJ : DT JJ\n",
    "        if the tlokano POS is a determiner and the next POS is an adj\n",
    "        eg. mabubuting : ken naimbag\n",
    "        \"\"\"\n",
    "        temp_next_adj = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_adj.append(temp_next_adj) \n",
    "        matched.append(wp_index + 1)\n",
    "        \n",
    "    elif curr_tl_pos == 'JJ' and next_tl_pos == 'DT' and next2_tl_pos == 'NN':    \n",
    "        \"\"\"\n",
    "        if JJ : JJ NN\n",
    "        if the tlokano POS is a determiner and the next POS is an adj\n",
    "        eg. mabubuting : ken naimbag\n",
    "        \"\"\"\n",
    "        temp_curr_adj = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_adj.append(temp_curr_adj) \n",
    "        matched.append(wp_index + 1)\n",
    "\n",
    "    else:\n",
    "        \"\"\"\n",
    "        if JJ : Other POS\n",
    "        if the tlokano POS is not an adj\n",
    "        \"\"\"\n",
    "        tl_adj.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        tl_adj_list.append(tl_adj)\n",
    "        if tl_adj[0] == 'None':\n",
    "            tl_adj_count.append(0)\n",
    "            tl_adj_count_tf.append(round((0/tl_sen_len), 6))\n",
    "        else:\n",
    "            tl_adj_count.append(1)\n",
    "            tl_adj_count_tf.append(round((1/tl_sen_len), 6))\n",
    "        tl_adj_count_list.append(tl_adj_count)\n",
    "        tl_adj_count_list_tf.append(tl_adj_count_tf)\n",
    "        \n",
    "        if tl_adj[0] not in tl_adj_sen:\n",
    "            tl_adj_sen.append(tl_adj[0])\n",
    "            if tl_adj[0] == 'None':\n",
    "                tl_adj_count_list_idf.append([0])\n",
    "            else:\n",
    "                tl_adj_count_list_idf.append([1])\n",
    "        else:\n",
    "            tl_adj_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if tl_adj[0] not in tl_adj_list[temp_index]:\n",
    "            tl_adj_list[temp_index].append(tl_adj[0]) # temp_index = row index of the adj\n",
    "            if tl_adj[0] == 'None':\n",
    "                tl_adj_count_list[temp_index].append(0)\n",
    "                tl_adj_count_list_tf[temp_index].append(round((0/tl_sen_len), 6))\n",
    "            else:\n",
    "                tl_adj_count_list[temp_index].append(1)\n",
    "                tl_adj_count_list_tf[temp_index].append(round((1/tl_sen_len), 6)) \n",
    "            \n",
    "            if tl_adj[0] not in tl_adj_sen: # tl_adj_sen = list of adjs in  a single sentence\n",
    "                tl_adj_sen.append(tl_adj[0])\n",
    "                if tl_adj[0] == 'None':\n",
    "                    tl_adj_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    tl_adj_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                tl_adj_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the adj is already in tl_adj_list\n",
    "            temp_adj_index = tl_adj_list[temp_index].index(tl_adj[0])\n",
    "            if tl_adj[0] == 'None':\n",
    "                tl_adj_count_list[temp_index][temp_adj_index] += 0\n",
    "                tl_adj_count_list_tf[temp_index][temp_adj_index] += (0/tl_sen_len)\n",
    "            else:\n",
    "                tl_adj_count_list[temp_index][temp_adj_index] += 1\n",
    "                tl_adj_count_list_tf[temp_index][temp_adj_index] += (1/tl_sen_len)\n",
    "            tl_adj_count_list_tf[temp_index][temp_adj_index] = round(tl_adj_count_list_tf[temp_index][temp_adj_index], 6)\n",
    "            \n",
    "            if tl_adj[0] not in tl_adj_sen:\n",
    "                tl_adj_sen.append(tl_adj[0])\n",
    "                if tl_adj[0] == 'None':\n",
    "                    tl_adj_count_list_idf[temp_index][temp_adj_index] += 0\n",
    "                else:\n",
    "                    tl_adj_count_list_idf[temp_index][temp_adj_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Adverb List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rb_list(il_adv, il_adv_list, tl_adv, tl_adv_list, curr_tl_pos, next_tl_pos, next2_tl_pos, next3_tl_pos, prev_tl_pos, matched, sp_index, wp_index, tl_adv_count_list, tl_adv_count, il_adv_count_list, il_adv_count, il_adv_term_count, il_adv_sen, il_adv_count_list_tf, il_sen_len, tl_adv_sen, tl_adv_count_list_idf, tl_adv_count_list_tf, tl_adv_count_tf, tl_sen_len):\n",
    "    \n",
    "    if il_adv not in il_adv_list:\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        il_adv_list.append(il_adv)\n",
    "        il_adv_count.append(1) \n",
    "        il_adv_term_count.append(il_adv_count)\n",
    "        \n",
    "        if il_adv not in il_adv_sen:\n",
    "            il_adv_sen.append(il_adv)\n",
    "            il_adv_count_list.append(1)\n",
    "            il_adv_count_list_tf.append([1/il_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = il_adv_list.index(il_adv)\n",
    "\n",
    "        temp_adv_index = il_adv_list[temp_index].index(il_adv[0])\n",
    "        il_adv_term_count[temp_index][temp_adv_index] += 1\n",
    "        \n",
    "        if il_adv not in il_adv_sen:\n",
    "            il_adv_sen.append(il_adv)\n",
    "            il_adv_count_list[temp_index] += 1\n",
    "            il_adv_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                il_adv_count_list_tf[temp_index][sp_index] += (1/il_sen_len)\n",
    "            except:\n",
    "                il_adv_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_tl_pos == 'RB':\n",
    "        \"\"\"\n",
    "        if RB : RB\n",
    "        if the tlokano POS is a adverb\n",
    "        \"\"\"\n",
    "        temp_adverb = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_adv.append(temp_adverb)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and next_tl_pos == 'RB':    \n",
    "        \"\"\"\n",
    "        if RB : DT RB\n",
    "        \"\"\"\n",
    "        temp_next_adverb = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_adv.append(temp_next_adverb) \n",
    "        matched.append(wp_index + 1)\n",
    "  \n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and next_tl_pos == 'NN' and next2_tl_pos == 'DT' and next3_tl_pos == 'RB' :  \n",
    "        \"\"\"\n",
    "        if RB : DT NN DT RB\n",
    "        \n",
    "        \"\"\"\n",
    "        temp_adverb = tl_pos_data['Tokenized'][sp_index][wp_index + 3]\n",
    "        tl_adv.append(temp_adverb)\n",
    "        matched.append(wp_index + 3)\n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and prev_tl_pos == 'RB':\n",
    "        \"\"\"\n",
    "        if RB : DT with RB behind DT\n",
    "        \n",
    "        \"\"\"\n",
    "        temp_adverb = tl_pos_data['Tokenized'][sp_index][wp_index - 1]\n",
    "        tl_adv.append(temp_adverb)\n",
    "        matched.append(wp_index - 1)\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if RB : Other POS\n",
    "        if the tlokano POS is not a adverb\n",
    "        \"\"\"\n",
    "        tl_adv.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        tl_adv_list.append(tl_adv)\n",
    "        if tl_adv[0] == 'None':\n",
    "            tl_adv_count.append(0)\n",
    "            tl_adv_count_tf.append(round((0/tl_sen_len), 6))\n",
    "        else:\n",
    "            tl_adv_count.append(1)\n",
    "            tl_adv_count_tf.append(round((1/tl_sen_len), 6))\n",
    "        tl_adv_count_list.append(tl_adv_count)\n",
    "        tl_adv_count_list_tf.append(tl_adv_count_tf)\n",
    "        \n",
    "        if tl_adv[0] not in tl_adv_sen:\n",
    "            tl_adv_sen.append(tl_adv[0])\n",
    "            if tl_adv[0] == 'None':\n",
    "                tl_adv_count_list_idf.append([0])\n",
    "            else:\n",
    "                tl_adv_count_list_idf.append([1])\n",
    "        else:\n",
    "            tl_adv_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if tl_adv[0] not in tl_adv_list[temp_index]:\n",
    "            tl_adv_list[temp_index].append(tl_adv[0]) # temp_index = row index of the adv\n",
    "            if tl_adv[0] == 'None':\n",
    "                tl_adv_count_list[temp_index].append(0)\n",
    "                tl_adv_count_list_tf[temp_index].append(round((0/tl_sen_len), 6))\n",
    "            else:\n",
    "                tl_adv_count_list[temp_index].append(1)\n",
    "                tl_adv_count_list_tf[temp_index].append(round((1/tl_sen_len), 6)) \n",
    "            \n",
    "            if tl_adv[0] not in tl_adv_sen: # tl_adv_sen = list of advs in  a single sentence\n",
    "                tl_adv_sen.append(tl_adv[0])\n",
    "                if tl_adv[0] == 'None':\n",
    "                    tl_adv_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    tl_adv_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                tl_adv_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the adv is already in tl_adv_list\n",
    "            temp_adv_index = tl_adv_list[temp_index].index(tl_adv[0])\n",
    "            if tl_adv[0] == 'None':\n",
    "                tl_adv_count_list[temp_index][temp_adv_index] += 0\n",
    "                tl_adv_count_list_tf[temp_index][temp_adv_index] += (0/tl_sen_len)\n",
    "            else:\n",
    "                tl_adv_count_list[temp_index][temp_adv_index] += 1\n",
    "                tl_adv_count_list_tf[temp_index][temp_adv_index] += (1/tl_sen_len)\n",
    "            tl_adv_count_list_tf[temp_index][temp_adv_index] = round(tl_adv_count_list_tf[temp_index][temp_adv_index], 6)\n",
    "            \n",
    "            if tl_adv[0] not in tl_adv_sen:\n",
    "                tl_adv_sen.append(tl_adv[0])\n",
    "                if tl_adv[0] == 'None':\n",
    "                    tl_adv_count_list_idf[temp_index][temp_adv_index] += 0\n",
    "                else:\n",
    "                    tl_adv_count_list_idf[temp_index][temp_adv_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Conjunction List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_cc_list(il_conj, il_conj_list, tl_conj, tl_conj_list, curr_tl_pos, matched, sp_index, wp_index, tl_conj_count_list, tl_conj_count, il_conj_count_list, il_conj_count, il_conj_term_count, il_conj_sen, il_conj_count_list_tf, il_sen_len, tl_conj_sen, tl_conj_count_list_idf, tl_conj_count_list_tf, tl_conj_count_tf, tl_sen_len):\n",
    "    \n",
    "    if il_conj not in il_conj_list: # il_conj_list = json ftle of verbs\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        il_conj_list.append(il_conj)\n",
    "        il_conj_count.append(1) \n",
    "        il_conj_term_count.append(il_conj_count)\n",
    "        \n",
    "        if il_conj not in il_conj_sen:\n",
    "            il_conj_sen.append(il_conj)\n",
    "            il_conj_count_list.append(1)\n",
    "            il_conj_count_list_tf.append([1/il_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = il_conj_list.index(il_conj)\n",
    "\n",
    "        temp_conj_index = il_conj_list[temp_index].index(il_conj[0])\n",
    "        il_conj_term_count[temp_index][temp_conj_index] += 1\n",
    "        \n",
    "        if il_conj not in il_conj_sen:\n",
    "            il_conj_sen.append(il_conj)\n",
    "            il_conj_count_list[temp_index] += 1\n",
    "            il_conj_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                il_conj_count_list_tf[temp_index][sp_index] += (1/il_sen_len)\n",
    "            except:\n",
    "                il_conj_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the conj in the tagalog conj\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_tl_pos == 'CC':\n",
    "        \"\"\"\n",
    "        if CC : CC\n",
    "        if the tlokano POS is a conj\n",
    "        \"\"\"\n",
    "        temp_conj = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_conj.append(temp_conj)\n",
    "        matched.append(wp_index)\n",
    "          \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if CC : Other POS\n",
    "        if the tlokano POS is not a conj\n",
    "        \"\"\"\n",
    "        tl_conj.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        tl_conj_list.append(tl_conj)\n",
    "        if tl_conj[0] == 'None':\n",
    "            tl_conj_count.append(0)\n",
    "            tl_conj_count_tf.append(round((0/tl_sen_len), 6))\n",
    "        else:\n",
    "            tl_conj_count.append(1)\n",
    "            tl_conj_count_tf.append(round((1/tl_sen_len), 6))\n",
    "        tl_conj_count_list.append(tl_conj_count)\n",
    "        tl_conj_count_list_tf.append(tl_conj_count_tf)\n",
    "        \n",
    "        if tl_conj[0] not in tl_conj_sen:\n",
    "            tl_conj_sen.append(tl_conj[0])\n",
    "            if tl_conj[0] == 'None':\n",
    "                tl_conj_count_list_idf.append([0])\n",
    "            else:\n",
    "                tl_conj_count_list_idf.append([1])\n",
    "        else:\n",
    "            tl_conj_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if tl_conj[0] not in tl_conj_list[temp_index]:\n",
    "            tl_conj_list[temp_index].append(tl_conj[0]) # temp_index = row index of the conj\n",
    "            if tl_conj[0] == 'None':\n",
    "                tl_conj_count_list[temp_index].append(0)\n",
    "                tl_conj_count_list_tf[temp_index].append(round((0/tl_sen_len), 6))\n",
    "            else:\n",
    "                tl_conj_count_list[temp_index].append(1)\n",
    "                tl_conj_count_list_tf[temp_index].append(round((1/tl_sen_len), 6)) \n",
    "            \n",
    "            if tl_conj[0] not in tl_conj_sen: # tl_conj_sen = list of conjs in  a single sentence\n",
    "                tl_conj_sen.append(tl_conj[0])\n",
    "                if tl_conj[0] == 'None':\n",
    "                    tl_conj_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    tl_conj_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                tl_conj_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the conj is already in tl_conj_list\n",
    "            temp_conj_index = tl_conj_list[temp_index].index(tl_conj[0])\n",
    "            if tl_conj[0] == 'None':\n",
    "                tl_conj_count_list[temp_index][temp_conj_index] += 0\n",
    "                tl_conj_count_list_tf[temp_index][temp_conj_index] += (0/tl_sen_len)\n",
    "            else:\n",
    "                tl_conj_count_list[temp_index][temp_conj_index] += 1\n",
    "                tl_conj_count_list_tf[temp_index][temp_conj_index] += (1/tl_sen_len)\n",
    "            tl_conj_count_list_tf[temp_index][temp_conj_index] = round(tl_conj_count_list_tf[temp_index][temp_conj_index], 6)\n",
    "            \n",
    "            if tl_conj[0] not in tl_conj_sen:\n",
    "                tl_conj_sen.append(tl_conj[0])\n",
    "                if tl_conj[0] == 'None':\n",
    "                    tl_conj_count_list_idf[temp_index][temp_conj_index] += 0\n",
    "                else:\n",
    "                    tl_conj_count_list_idf[temp_index][temp_conj_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Preposition List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_pr_list(il_prepo, il_prepo_list, tl_prepo, tl_prepo_list, curr_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_prepo_count_list, tl_prepo_count, il_prepo_count_list, il_prepo_count, il_prepo_term_count, il_prepo_sen, il_prepo_count_list_tf, il_sen_len, tl_prepo_sen, tl_prepo_count_list_idf, tl_prepo_count_list_tf, tl_prepo_count_tf, tl_sen_len):\n",
    "    \n",
    "    if il_prepo not in il_prepo_list: # il_prepo_list = json ftle of verbs\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        il_prepo_list.append(il_prepo)\n",
    "        il_prepo_count.append(1) \n",
    "        il_prepo_term_count.append(il_prepo_count)\n",
    "        \n",
    "        if il_prepo not in il_prepo_sen:\n",
    "            il_prepo_sen.append(il_prepo)\n",
    "            il_prepo_count_list.append(1)\n",
    "            il_prepo_count_list_tf.append([1/il_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = il_prepo_list.index(il_prepo)\n",
    "\n",
    "        temp_prepo_index = il_prepo_list[temp_index].index(il_prepo[0])\n",
    "        il_prepo_term_count[temp_index][temp_prepo_index] += 1\n",
    "        \n",
    "        if il_prepo not in il_prepo_sen:\n",
    "            il_prepo_sen.append(il_prepo)\n",
    "            il_prepo_count_list[temp_index] += 1\n",
    "            il_prepo_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                il_prepo_count_list_tf[temp_index][sp_index] += (1/il_sen_len)\n",
    "            except:\n",
    "                il_prepo_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "    \n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "    \n",
    "    if curr_tl_pos == 'PR' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : PR\n",
    "        if the tlokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_prepo = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_prepo.append(temp_prepo)\n",
    "        matched.append(wp_index)\n",
    "    if curr_tl_pos == 'DT' and next_tl_pos == 'PR' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : PR\n",
    "        if the tlokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_prepo = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_prepo.append(temp_prepo)\n",
    "        matched.append(wp_index + 1)\n",
    "    if curr_tl_pos == 'DT' and next_tl_pos == 'PR' and next2_tl_pos == 'DT' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : DT PR DT\n",
    "        if the tlokano prepo is sandwiched between 2 determiners\n",
    "        \"\"\"\n",
    "        temp_prepo = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_prepo.append(temp_prepo)\n",
    "        matched.append(wp_index + 1)\n",
    "    if curr_tl_pos == 'PR' and next_tl_pos == 'DT' and next2_tl_pos == 'NN' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : DT PR DT\n",
    "        if the tlokano prepo is sandwiched between 2 determiners\n",
    "        \"\"\"\n",
    "        temp_prepo = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_prepo.append(temp_prepo)\n",
    "        matched.append(wp_index)\n",
    "    \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if VB : Other POS\n",
    "        if the tlokano POS is not a verb\n",
    "        \"\"\"\n",
    "        tl_prepo.append('None')\n",
    "        matched.append(wp_index)\n",
    "    \n",
    "    if not inDict:\n",
    "        tl_prepo_list.append(tl_prepo)\n",
    "        if tl_prepo[0] == 'None':\n",
    "            tl_prepo_count.append(0)\n",
    "            tl_prepo_count_tf.append(round((0/tl_sen_len), 6))\n",
    "        else:\n",
    "            tl_prepo_count.append(1)\n",
    "            tl_prepo_count_tf.append(round((1/tl_sen_len), 6))\n",
    "        tl_prepo_count_list.append(tl_prepo_count)\n",
    "        tl_prepo_count_list_tf.append(tl_prepo_count_tf)\n",
    "        \n",
    "        if tl_prepo[0] not in tl_prepo_sen:\n",
    "            tl_prepo_sen.append(tl_prepo[0])\n",
    "            if tl_prepo[0] == 'None':\n",
    "                tl_prepo_count_list_idf.append([0])\n",
    "            else:\n",
    "                tl_prepo_count_list_idf.append([1])\n",
    "        else:\n",
    "            tl_prepo_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if tl_prepo[0] not in tl_prepo_list[temp_index]:\n",
    "            tl_prepo_list[temp_index].append(tl_prepo[0]) # temp_index = row index of the prepo\n",
    "            if tl_prepo[0] == 'None':\n",
    "                tl_prepo_count_list[temp_index].append(0)\n",
    "                tl_prepo_count_list_tf[temp_index].append(round((0/tl_sen_len), 6))\n",
    "            else:\n",
    "                tl_prepo_count_list[temp_index].append(1)\n",
    "                tl_prepo_count_list_tf[temp_index].append(round((1/tl_sen_len), 6)) \n",
    "            \n",
    "            if tl_prepo[0] not in tl_prepo_sen: # tl_prepo_sen = list of prepos in  a single sentence\n",
    "                tl_prepo_sen.append(tl_prepo[0])\n",
    "                if tl_prepo[0] == 'None':\n",
    "                    tl_prepo_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    tl_prepo_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                tl_prepo_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the prepo is already in tl_prepo_list\n",
    "            temp_prepo_index = tl_prepo_list[temp_index].index(tl_prepo[0])\n",
    "            if tl_prepo[0] == 'None':\n",
    "                tl_prepo_count_list[temp_index][temp_prepo_index] += 0\n",
    "                tl_prepo_count_list_tf[temp_index][temp_prepo_index] += (0/tl_sen_len)\n",
    "            else:\n",
    "                tl_prepo_count_list[temp_index][temp_prepo_index] += 1\n",
    "                tl_prepo_count_list_tf[temp_index][temp_prepo_index] += (1/tl_sen_len)\n",
    "            tl_prepo_count_list_tf[temp_index][temp_prepo_index] = round(tl_prepo_count_list_tf[temp_index][temp_prepo_index], 6)\n",
    "            \n",
    "            if tl_prepo[0] not in tl_prepo_sen:\n",
    "                tl_prepo_sen.append(tl_prepo[0])\n",
    "                if tl_prepo[0] == 'None':\n",
    "                    tl_prepo_count_list_idf[temp_index][temp_prepo_index] += 0\n",
    "                else:\n",
    "                    tl_prepo_count_list_idf[temp_index][temp_prepo_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Determiner List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_dt_list(il_dt, il_dt_list, tl_dt, tl_dt_list, curr_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_dt_count_list, tl_dt_count, il_dt_count_list, il_dt_count, il_dt_term_count, il_dt_sen, il_dt_count_list_tf, il_sen_len, tl_dt_sen, tl_dt_count_list_idf, tl_dt_count_list_tf, tl_dt_count_tf, tl_sen_len):\n",
    "    \n",
    "    if il_dt not in il_dt_list: # il_dt_list = json ftle of verbs\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        il_dt_list.append(il_dt)\n",
    "        il_dt_count.append(1) \n",
    "        il_dt_term_count.append(il_dt_count)\n",
    "        \n",
    "        if il_dt not in il_dt_sen:\n",
    "            il_dt_sen.append(il_dt)\n",
    "            il_dt_count_list.append(1)\n",
    "            il_dt_count_list_tf.append([1/il_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = il_dt_list.index(il_dt)\n",
    "\n",
    "        temp_dt_index = il_dt_list[temp_index].index(il_dt[0])\n",
    "        il_dt_term_count[temp_index][temp_dt_index] += 1\n",
    "        \n",
    "        if il_dt not in il_dt_sen:\n",
    "            il_dt_sen.append(il_dt)\n",
    "            il_dt_count_list[temp_index] += 1\n",
    "            il_dt_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                il_dt_count_list_tf[temp_index][sp_index] += (1/il_sen_len)\n",
    "            except:\n",
    "                il_dt_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "    \n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "    \n",
    "    if curr_tl_pos == 'DT' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : PR\n",
    "        if the tlokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_prepo = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_dt.append(temp_prepo)\n",
    "        matched.append(wp_index)\n",
    "    \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if VB : Other POS\n",
    "        if the tlokano POS is not a verb\n",
    "        \"\"\"\n",
    "        tl_dt.append('None')\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    if not inDict:\n",
    "        tl_dt_list.append(tl_dt)\n",
    "        if tl_dt[0] == 'None':\n",
    "            tl_dt_count.append(0)\n",
    "            tl_dt_count_tf.append(round((0/tl_sen_len), 6))\n",
    "        else:\n",
    "            tl_dt_count.append(1)\n",
    "            tl_dt_count_tf.append(round((1/tl_sen_len), 6))\n",
    "        tl_dt_count_list.append(tl_dt_count)\n",
    "        tl_dt_count_list_tf.append(tl_dt_count_tf)\n",
    "        \n",
    "        if tl_dt[0] not in tl_dt_sen:\n",
    "            tl_dt_sen.append(tl_dt[0])\n",
    "            if tl_dt[0] == 'None':\n",
    "                tl_dt_count_list_idf.append([0])\n",
    "            else:\n",
    "                tl_dt_count_list_idf.append([1])\n",
    "        else:\n",
    "            tl_dt_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if tl_dt[0] not in tl_dt_list[temp_index]:\n",
    "            tl_dt_list[temp_index].append(tl_dt[0]) # temp_index = row index of the dt\n",
    "            if tl_dt[0] == 'None':\n",
    "                tl_dt_count_list[temp_index].append(0)\n",
    "                tl_dt_count_list_tf[temp_index].append(round((0/tl_sen_len), 6))\n",
    "            else:\n",
    "                tl_dt_count_list[temp_index].append(1)\n",
    "                tl_dt_count_list_tf[temp_index].append(round((1/tl_sen_len), 6)) \n",
    "            \n",
    "            if tl_dt[0] not in tl_dt_sen: # tl_dt_sen = list of dts in  a single sentence\n",
    "                tl_dt_sen.append(tl_dt[0])\n",
    "                if tl_dt[0] == 'None':\n",
    "                    tl_dt_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    tl_dt_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                tl_dt_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the dt is already in tl_dt_list\n",
    "            temp_dt_index = tl_dt_list[temp_index].index(tl_dt[0])\n",
    "            if tl_dt[0] == 'None':\n",
    "                tl_dt_count_list[temp_index][temp_dt_index] += 0\n",
    "                tl_dt_count_list_tf[temp_index][temp_dt_index] += (0/tl_sen_len)\n",
    "            else:\n",
    "                tl_dt_count_list[temp_index][temp_dt_index] += 1\n",
    "                tl_dt_count_list_tf[temp_index][temp_dt_index] += (1/tl_sen_len)\n",
    "            tl_dt_count_list_tf[temp_index][temp_dt_index] = round(tl_dt_count_list_tf[temp_index][temp_dt_index], 6)\n",
    "            \n",
    "            if tl_dt[0] not in tl_dt_sen:\n",
    "                tl_dt_sen.append(tl_dt[0])\n",
    "                if tl_dt[0] == 'None':\n",
    "                    tl_dt_count_list_idf[temp_index][temp_dt_index] += 0\n",
    "                else:\n",
    "                    tl_dt_count_list_idf[temp_index][temp_dt_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_idf(tl_count_list):\n",
    "    tl_idf = []\n",
    "    for tl_count in tl_count_list:\n",
    "        temp_quo = tl_doc_len/tl_count\n",
    "        tl_idf.append(abs(math.log10(temp_quo)))\n",
    "        \n",
    "    return tl_idf\n",
    "# end of get_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf_il(il_verb_count_list_idf):\n",
    "    il_idf_list = []\n",
    "    for il_count_list in il_verb_count_list_idf:\n",
    "        il_idf = []\n",
    "        for il_count in il_count_list:\n",
    "            try:\n",
    "                temp_quo = il_doc_len/il_count\n",
    "                il_idf.append(round(abs(math.log10(temp_quo)), 6))\n",
    "            except:\n",
    "                temp_quo = 0\n",
    "                il_idf.append(0)\n",
    "                \n",
    "        il_idf_list.append(il_idf)\n",
    "    return il_idf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_il(il_count_sen_list, il_verb_count_list_tf):\n",
    "    il_tf_list = []\n",
    "    \n",
    "    for il_count_list in il_verb_count_list_tf:\n",
    "        il_tf = []\n",
    "\n",
    "        for il_count_sen in il_count_sen_list:\n",
    "            temp_sum = 0\n",
    "            \n",
    "            for il_count in il_count_sen:\n",
    "                temp_sum += il_count\n",
    "                \n",
    "            temp_len = len(il_count_sen)\n",
    "            temp_quo = temp_sum/temp_len\n",
    "            il_tf.append(round(temp_quo, 6))\n",
    "        \n",
    "    return il_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(tl_count_sen_list):\n",
    "    tl_tf = []\n",
    "\n",
    "    for tl_count_sen in tl_count_sen_list:\n",
    "        temp_sum = 0\n",
    "        \n",
    "        for tl_count in tl_count_sen:\n",
    "            temp_sum += tl_count\n",
    "            \n",
    "        temp_len = len(tl_count_sen)\n",
    "        temp_quo = temp_sum/temp_len\n",
    "        tl_tf.append(round(temp_quo, 6))\n",
    "        \n",
    "    return tl_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf(tl_tf, tl_idf):\n",
    "    tf_idf_tl = []\n",
    "    \n",
    "    for i in range(len(tl_tf)):\n",
    "        temp_score = tl_tf[i] * tl_idf[i]\n",
    "        tf_idf_tl.append(round(temp_score, 2))\n",
    "        \n",
    "    return tf_idf_tl\n",
    "# end of get_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf_il(il_tf_list, il_idf_list):\n",
    "    il_tf_idf_list = []\n",
    "    \n",
    "    for i in range(len(il_tf_list)):\n",
    "        il_tf_idf = []\n",
    "        for j in range(len(il_tf_list[i])):\n",
    "            temp_score = il_tf_list[i][j] * il_idf_list[i][j]\n",
    "            il_tf_idf.append(round(temp_score, 2))\n",
    "            \n",
    "        il_tf_idf_list.append(il_tf_idf)\n",
    "        \n",
    "    return il_tf_idf_list\n",
    "# end of get_tf_idf_il"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagalog to Ilokano Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "wp_index = None # word position index\n",
    "\n",
    "\"\"\"\n",
    "instantiating the verb lists\n",
    "\"\"\"\n",
    "\n",
    "def match_il_tl_pos():\n",
    "    \"\"\"\n",
    "    This function matches the POS of the sentences in the Tagalog and Ilokano datasets\n",
    "    \"\"\"\n",
    "    sp_index = 0\n",
    "    \n",
    "    il_sw_list = []\n",
    "    tl_sw_list = []\n",
    "    il_verb_list = []\n",
    "    tl_verb_list = []\n",
    "    il_noun_list = []\n",
    "    tl_noun_list = []\n",
    "    il_adj_list = []\n",
    "    tl_adj_list = []\n",
    "    il_adv_list = []\n",
    "    tl_adv_list = []\n",
    "    il_conj_list = []\n",
    "    tl_conj_list = []\n",
    "    il_prepo_list = []\n",
    "    tl_prepo_list = []\n",
    "    il_dt_list = []\n",
    "    tl_dt_list = []\n",
    "    il_to_tl_verb_list = []\n",
    "    \"\"\"\n",
    "    instantiating the verb lists\n",
    "    \"\"\"\n",
    "    \n",
    "    tl_verb_count_list = []\n",
    "    tl_noun_count_list = []\n",
    "    tl_adj_count_list = []\n",
    "    tl_adv_count_list = []\n",
    "    tl_conj_count_list = []\n",
    "    tl_prepo_count_list = []\n",
    "    tl_dt_count_list = []\n",
    "    \n",
    "    il_verb_count_list = []\n",
    "    il_noun_count_list = []\n",
    "    il_adj_count_list = []\n",
    "    il_adv_count_list = []\n",
    "    il_conj_count_list = []\n",
    "    il_prepo_count_list = []\n",
    "    il_dt_count_list = []\n",
    "\n",
    "    il_verb_count_list_tf = []\n",
    "    il_noun_count_list_tf = []\n",
    "    il_adj_count_list_tf = []\n",
    "    il_adv_count_list_tf = []\n",
    "    il_conj_count_list_tf = []\n",
    "    il_prepo_count_list_tf = []\n",
    "    il_dt_count_list_tf = []\n",
    "\n",
    "    tl_verb_count_list_tf = []\n",
    "    tl_noun_count_list_tf = []\n",
    "    tl_adj_count_list_tf = []\n",
    "    tl_adv_count_list_tf = []\n",
    "    tl_conj_count_list_tf = []\n",
    "    tl_prepo_count_list_tf = []\n",
    "    tl_dt_count_list_tf = []\n",
    "\n",
    "    il_verb_term_count = []\n",
    "    il_noun_term_count = []\n",
    "    il_adj_term_count = []\n",
    "    il_adv_term_count = []\n",
    "    il_conj_term_count = []\n",
    "    il_prepo_term_count = []\n",
    "    il_dt_term_count = []\n",
    "    \n",
    "    il_sen_len_list = []\n",
    "    tl_sen_len_list = []\n",
    "    \n",
    "    tl_verb_count_list_idf = []\n",
    "    tl_noun_count_list_idf = []\n",
    "    tl_adj_count_list_idf = []\n",
    "    tl_adv_count_list_idf = []\n",
    "    tl_conj_count_list_idf = []\n",
    "    tl_prepo_count_list_idf = []\n",
    "    tl_dt_count_list_idf = []\n",
    "    \n",
    "    tl_verb_count_list_tf = []\n",
    "    tl_noun_count_list_tf = []\n",
    "    tl_adj_count_list_tf = []\n",
    "    tl_adv_count_list_tf = []\n",
    "    tl_conj_count_list_tf = []\n",
    "    tl_prepo_count_list_tf = []\n",
    "    tl_dt_count_list_tf = []\n",
    "    \n",
    "    for il_sen_pos in il_sen_poss_list:\n",
    "        # loop for getting the pos structure of every sentence\n",
    "        \"\"\"\n",
    "        il_sen is a list of POS of a sentence\n",
    "        eg. ['VB', 'DT', 'NN', 'DT', 'NN']\n",
    "        \"\"\"\n",
    "        matched = []\n",
    "        tl_sen = tl_sen_poss_list[sp_index]\n",
    "        tl_sen_len = len(tl_sen)\n",
    "        il_sen_len = len(il_sen_pos)\n",
    "        tl_sen_len = len(tl_sen)\n",
    "        \n",
    "        il_sen_len_list.append(il_sen_len)\n",
    "        tl_sen_len_list.append(tl_sen_len)\n",
    "        \n",
    "        wp_index = 0\n",
    "        \"\"\"\n",
    "        instantiating the variables\n",
    "        \"\"\"\n",
    "        \n",
    "        il_verb_sen = []\n",
    "        il_noun_sen = []\n",
    "        il_adj_sen = []\n",
    "        il_adv_sen = []\n",
    "        il_conj_sen = []\n",
    "        il_prepo_sen = []\n",
    "        il_dt_sen = []\n",
    "        \n",
    "        tl_verb_sen = []\n",
    "        tl_noun_sen = []\n",
    "        tl_adj_sen = []\n",
    "        tl_adv_sen = []\n",
    "        tl_conj_sen = []\n",
    "        tl_prepo_sen = []\n",
    "        tl_dt_sen = []\n",
    "        \n",
    "        for il_word_pos in il_sen_pos:\n",
    "            # loop for eail pos in a sentence\n",
    "            \"\"\"\n",
    "            il_word_pos is a POS of a word\n",
    "            eg. 'VB'\n",
    "            \"\"\"\n",
    "            \n",
    "            tl_verb = []\n",
    "            tl_noun = []\n",
    "            tl_adj = []\n",
    "            tl_adv = []\n",
    "            tl_conj = []\n",
    "            tl_prepo = []\n",
    "            tl_dt = []\n",
    "            \n",
    "            tl_verb_count = []\n",
    "            tl_noun_count = []\n",
    "            tl_adj_count = []\n",
    "            tl_adv_count = []\n",
    "            tl_conj_count = []\n",
    "            tl_prepo_count = []\n",
    "            tl_dt_count = []\n",
    "            \n",
    "            tl_verb_count_tf = []\n",
    "            tl_noun_count_tf = []\n",
    "            tl_adj_count_tf = []\n",
    "            tl_adv_count_tf = []\n",
    "            tl_conj_count_tf = []\n",
    "            tl_prepo_count_tf = []\n",
    "            tl_dt_count_tf = []\n",
    "\n",
    "            il_verb_count = []\n",
    "            il_noun_count = []\n",
    "            il_adj_count = []\n",
    "            il_adv_count = []\n",
    "            il_conj_count = []\n",
    "            il_prepo_count = []\n",
    "            il_dt_count = []\n",
    "            \n",
    "            \n",
    "            il_word = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "            # gets the word in every sentence\n",
    "            \n",
    "            try:\n",
    "                curr_tl_pos = tl_sen[wp_index] # ti\n",
    "            except IndexError:\n",
    "                curr_tl_pos = 'None'\n",
    "            try:\n",
    "                next_tl_pos = tl_sen[wp_index + 1]\n",
    "            except IndexError:\n",
    "                next_tl_pos = 'None'\n",
    "            try:\n",
    "                next2_tl_pos = tl_sen[wp_index + 2]\n",
    "            except IndexError:\n",
    "                next2_tl_pos = 'None'\n",
    "            try:\n",
    "                next3_tl_pos = tl_sen[wp_index + 3]\n",
    "            except IndexError:\n",
    "                next3_tl_pos = 'None'\n",
    "            try:\n",
    "                prev_tl_pos = tl_sen[wp_index - 1]\n",
    "                if (wp_index - 1) < 0:\n",
    "                    prev_tl_pos = 'None'\n",
    "            except IndexError:\n",
    "                prev_tl_pos = 'None'\n",
    "            \"\"\"\n",
    "            getting the current, next, and previous POS in the sentence\n",
    "            \"\"\"\n",
    "            \n",
    "            # matching Conditions\n",
    "            \n",
    "            # 1. SW\n",
    "            if il_word_pos == 'SW':\n",
    "                \"\"\"\n",
    "                if SW : SW\n",
    "                if the Tagalog POS is a SW\n",
    "                \"\"\"\n",
    "                tl_word = tl_pos_data['Tokenized'][sp_index]\n",
    "                il_sw_list.append(il_word)\n",
    "                tl_sw_list.append(tl_word)\n",
    "            \n",
    "            # 2. VB\n",
    "            if il_word_pos == 'VB':\n",
    "                \"\"\"\n",
    "                Verb matching\n",
    "                if the POS is a verb, append the index of the verb to the verb list\n",
    "                \"\"\"\n",
    "                \n",
    "                append_vb_list(il_word, il_verb_list, tl_verb, tl_verb_list, curr_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_verb_count_list, tl_verb_count, il_verb_count_list, il_verb_count, il_verb_term_count, il_verb_sen, il_verb_count_list_tf, il_sen_len, tl_verb_sen, tl_verb_count_list_idf, tl_verb_count_list_tf, tl_verb_count_tf, tl_sen_len)\n",
    "                \n",
    "            # 3. NN\n",
    "            if il_word_pos == 'NN':\n",
    "                \"\"\"\n",
    "                Noun matching\n",
    "                if the POS is a noun, append the index of the noun to the noun list\n",
    "                \"\"\"\n",
    "                append_nn_list(il_word, il_noun_list, tl_noun, tl_noun_list, curr_tl_pos, next_tl_pos, matched, sp_index, wp_index, tl_noun_count_list, tl_noun_count, il_noun_count_list, il_noun_count, il_noun_term_count, il_noun_sen, il_noun_count_list_tf, il_sen_len, tl_noun_sen, tl_noun_count_list_idf, tl_noun_count_list_tf, tl_noun_count_tf, tl_sen_len)\n",
    "\n",
    "            # 4. JJ\n",
    "            if il_word_pos == 'JJ':\n",
    "                \"\"\"\n",
    "                Adj matching\n",
    "                if the POS is a adj, append the index of the adj to the adj list\n",
    "                \"\"\"\n",
    "                append_jj_list(il_word, il_adj_list, tl_adj, tl_adj_list, curr_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_adj_count_list, tl_adj_count, il_adj_count_list, il_adj_count, il_adj_term_count, il_adj_sen, il_adj_count_list_tf, il_sen_len, tl_adj_sen, tl_adj_count_list_idf, tl_adj_count_list_tf, tl_adj_count_tf, tl_sen_len)\n",
    "            \n",
    "            # 5. RB\n",
    "            if il_word_pos == 'RB':\n",
    "                \"\"\"\n",
    "                Adverb matching\n",
    "                if the POS is a adverb, append the index of the adverb to the adverb list\n",
    "                \"\"\"\n",
    "                append_rb_list(il_word, il_adv_list, tl_adv, tl_adv_list, curr_tl_pos, next_tl_pos, next2_tl_pos, next3_tl_pos, prev_tl_pos, matched, sp_index, wp_index, tl_adv_count_list, tl_adv_count, il_adv_count_list, il_adv_count, il_adv_term_count, il_adv_sen, il_adv_count_list_tf, il_sen_len, tl_adv_sen, tl_adv_count_list_idf, tl_adv_count_list_tf, tl_adv_count_tf, tl_sen_len)\n",
    "            \n",
    "            # 6. CC\n",
    "            if il_word_pos == 'CC':\n",
    "                \"\"\"\n",
    "                Conjunction matching\n",
    "                if the POS is a conjunction, append the index of the conjunction to the conjunction list\n",
    "                \"\"\"\n",
    "                append_cc_list(il_word, il_conj_list, tl_conj, tl_conj_list, curr_tl_pos, matched, sp_index, wp_index, tl_conj_count_list, tl_conj_count, il_conj_count_list, il_conj_count, il_conj_term_count, il_conj_sen, il_conj_count_list_tf, il_sen_len, tl_conj_sen, tl_conj_count_list_idf, tl_conj_count_list_tf, tl_conj_count_tf, tl_sen_len)\n",
    "            \n",
    "            # 7. PR\n",
    "            if il_word_pos == 'PR':\n",
    "                \"\"\"\n",
    "                Preposition matching\n",
    "                if the POS is a preposition, append the index of the conjunction to the conjunction list\n",
    "                \"\"\"\n",
    "                append_pr_list(il_word, il_prepo_list, tl_prepo, tl_prepo_list, curr_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_prepo_count_list, tl_prepo_count, il_prepo_count_list, il_prepo_count, il_prepo_term_count, il_prepo_sen, il_prepo_count_list_tf, il_sen_len, tl_prepo_sen, tl_prepo_count_list_idf, tl_prepo_count_list_tf, tl_prepo_count_tf, tl_sen_len)\n",
    "            \n",
    "            # 8. DT\n",
    "            if il_word_pos == 'DT':\n",
    "                \"\"\"\n",
    "                Determiner matching\n",
    "                if the POS is a determiner, append the index of the conjunction to the conjunction list\n",
    "                \"\"\"\n",
    "                append_dt_list(il_word, il_dt_list, tl_dt, tl_dt_list, curr_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_dt_count_list, tl_dt_count, il_dt_count_list, il_dt_count, il_dt_term_count, il_dt_sen, il_dt_count_list_tf, il_sen_len, tl_dt_sen, tl_dt_count_list_idf, tl_dt_count_list_tf, tl_dt_count_tf, tl_sen_len)\n",
    "            \n",
    "                          \n",
    "            wp_index += 1  \n",
    "        sp_index += 1\n",
    "    \n",
    "    il_verb_idf = get_idf(il_verb_count_list)\n",
    "    il_noun_idf = get_idf(il_noun_count_list)\n",
    "    il_adj_idf = get_idf(il_adj_count_list)\n",
    "    il_adv_idf = get_idf(il_adv_count_list)\n",
    "    il_conj_idf = get_idf(il_conj_count_list)\n",
    "    il_prepo_idf = get_idf(il_prepo_count_list)\n",
    "    il_dt_idf = get_idf(il_dt_count_list)\n",
    "\n",
    "    il_verb_tf = get_tf(il_verb_count_list_tf)\n",
    "    il_noun_tf = get_tf(il_noun_count_list_tf)\n",
    "    il_adj_tf = get_tf(il_adj_count_list_tf)\n",
    "    il_adv_tf = get_tf(il_adv_count_list_tf)\n",
    "    il_conj_tf = get_tf(il_conj_count_list_tf)\n",
    "    il_prepo_tf = get_tf(il_prepo_count_list_tf)\n",
    "    il_dt_tf = get_tf(il_dt_count_list_tf)\n",
    "    \n",
    "    il_verb_tf_idf = get_tf_idf(il_verb_tf, il_verb_idf)\n",
    "    il_noun_tf_idf = get_tf_idf(il_noun_tf, il_noun_idf)\n",
    "    il_adj_tf_idf = get_tf_idf(il_adj_tf, il_adj_idf)\n",
    "    il_adv_tf_idf = get_tf_idf(il_adv_tf, il_adv_idf)\n",
    "    il_conj_tf_idf = get_tf_idf(il_conj_tf, il_conj_idf)\n",
    "    il_prepo_tf_idf = get_tf_idf(il_prepo_tf, il_prepo_idf)\n",
    "    il_dt_tf_idf = get_tf_idf(il_dt_tf, il_dt_idf)\n",
    "        \n",
    "    tl_verb_idf = get_idf_il(tl_verb_count_list_idf)\n",
    "    tl_noun_idf = get_idf_il(tl_noun_count_list_idf)\n",
    "    tl_adj_idf = get_idf_il(tl_adj_count_list_idf)\n",
    "    tl_adv_idf = get_idf_il(tl_adv_count_list_idf)\n",
    "    tl_conj_idf = get_idf_il(tl_conj_count_list_idf)\n",
    "    tl_prepo_idf = get_idf_il(tl_prepo_count_list_idf)\n",
    "    tl_dt_idf = get_idf_il(tl_dt_count_list_idf)\n",
    "    \n",
    "    tl_verb_tf_idf = get_tf_idf_il(tl_verb_count_list_tf, tl_verb_idf)\n",
    "    tl_noun_tf_idf = get_tf_idf_il(tl_noun_count_list_tf, tl_noun_idf)\n",
    "    tl_adj_tf_idf = get_tf_idf_il(tl_adj_count_list_tf, tl_adj_idf)\n",
    "    tl_adv_tf_idf = get_tf_idf_il(tl_adv_count_list_tf, tl_adv_idf)\n",
    "    tl_conj_tf_idf = get_tf_idf_il(tl_conj_count_list_tf, tl_conj_idf)\n",
    "    tl_prepo_tf_idf = get_tf_idf_il(tl_prepo_count_list_tf, tl_prepo_idf)\n",
    "    tl_dt_tf_idf = get_tf_idf_il(tl_dt_count_list_tf, tl_dt_idf)\n",
    "    \n",
    "    dict_il_tl_sw['Ilokano Single Words'] = il_sw_list\n",
    "    dict_il_tl_sw['Tagalog Single Words'] = tl_sw_list\n",
    "    \n",
    "    dict_il_tl_vb['Ilokano Verb'] = il_verb_list\n",
    "    dict_il_tl_vb['Ilokano Verb TF-IDF'] = il_verb_tf_idf\n",
    "    dict_il_tl_vb['Ilokano Verb Count'] = il_verb_term_count\n",
    "    dict_il_tl_vb['Tagalog Verb'] = tl_verb_list\n",
    "    dict_il_tl_vb['Tagalog Verb Count'] = tl_verb_count_list\n",
    "    dict_il_tl_vb['Tagalog Verb TF-IDF'] = tl_verb_tf_idf\n",
    "    \n",
    "    dict_il_tl_nn['Ilokano Noun'] = il_noun_list\n",
    "    dict_il_tl_nn['Ilokano Noun TF-IDF'] = il_noun_tf_idf\n",
    "    dict_il_tl_nn['Ilokano Noun Count'] = il_noun_count_list\n",
    "    dict_il_tl_nn['Tagalog Noun'] = tl_noun_list\n",
    "    dict_il_tl_nn['Tagalog Noun Count'] = tl_noun_count_list\n",
    "    dict_il_tl_nn['Tagalog Noun TF-IDF'] = tl_noun_tf_idf\n",
    "    \n",
    "    dict_il_tl_jj['Ilokano Adjective'] = il_adj_list\n",
    "    dict_il_tl_jj['Ilokano Adjective TF-IDF'] = il_adj_tf_idf\n",
    "    dict_il_tl_jj['Ilokano Adjective Count'] = il_adj_count_list\n",
    "    dict_il_tl_jj['Tagalog Adjective'] = tl_adj_list\n",
    "    dict_il_tl_jj['Tagalog Adjective Count'] = tl_adj_count_list\n",
    "    dict_il_tl_jj['Tagalog Adjective TF-IDF'] = tl_adj_tf_idf\n",
    "\n",
    "    dict_il_tl_rb['Ilokano Adverb'] = il_adv_list\n",
    "    dict_il_tl_rb['Ilokano Adverb TF-IDF'] = il_adv_tf_idf\n",
    "    dict_il_tl_rb['Ilokano Adverb Count'] = il_adv_count_list\n",
    "    dict_il_tl_rb['Tagalog Adverb'] = tl_adv_list\n",
    "    dict_il_tl_rb['Tagalog Adverb Count'] = tl_adv_count_list\n",
    "    dict_il_tl_rb['Tagalog Adverb TF-IDF'] = tl_adv_tf_idf\n",
    "\n",
    "    dict_il_tl_cc['Ilokano Conjunction'] = il_conj_list\n",
    "    dict_il_tl_cc['Ilokano Conjunction TF-IDF'] = il_conj_tf_idf\n",
    "    dict_il_tl_cc['Ilokano Conjunction Count'] = il_conj_count_list\n",
    "    dict_il_tl_cc['Tagalog Conjunction'] = tl_conj_list\n",
    "    dict_il_tl_cc['Tagalog Conjunction Count'] = tl_conj_count_list\n",
    "    dict_il_tl_cc['Tagalog Conjunction TF-IDF'] = tl_conj_tf_idf\n",
    "\n",
    "    dict_il_tl_pr['Ilokano Preposition'] = il_prepo_list\n",
    "    dict_il_tl_pr['Ilokano Preposition TF-IDF'] = il_prepo_tf_idf\n",
    "    dict_il_tl_pr['Ilokano Preposition Count'] = il_prepo_count_list\n",
    "    dict_il_tl_pr['Tagalog Preposition'] = tl_prepo_list\n",
    "    dict_il_tl_pr['Tagalog Preposition Count'] = tl_prepo_count_list\n",
    "    dict_il_tl_pr['Tagalog Preposition TF-IDF'] = tl_prepo_tf_idf\n",
    "    \n",
    "    dict_il_tl_dt['Ilokano Determiner'] = il_dt_list\n",
    "    dict_il_tl_dt['Ilokano Determiner TF-IDF'] = il_dt_tf_idf\n",
    "    dict_il_tl_dt['Ilokano Determiner Count'] = il_dt_count_list\n",
    "    dict_il_tl_dt['Tagalog Determiner'] = tl_dt_list\n",
    "    dict_il_tl_dt['Tagalog Determiner Count'] = tl_dt_count_list\n",
    "    dict_il_tl_dt['Tagalog Determiner TF-IDF'] = tl_dt_tf_idf\n",
    "    \n",
    "match_il_tl_pos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_il_tl_sw.head()\n",
    "# dict_il_tl_vb.head(50)\n",
    "# dict_il_tl_nn.head(50)\n",
    "# dict_il_tl_jj.head(50)\n",
    "# dict_il_tl_rb.head(50)\n",
    "# dict_il_tl_cc.head(50)\n",
    "# dict_il_tl_pr.head(50)\n",
    "dict_il_tl_dt.head(50)\n",
    "\n",
    "# temp_dict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the dictionary in the json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Single Word Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dict_sw = dict_il_tl_sw.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_sw.json\", \"w\") as outfile:\n",
    "        json.dump(dict_sw, outfile)\n",
    "    print(\"successfully saved the dict_sw.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_sw.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Verb Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_vb = dict_il_tl_vb.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_vb.json\", \"w\") as outfile:\n",
    "        json.dump(dict_vb, outfile)\n",
    "    print(\"successfully saved the dict_vb.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_vb.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Noun Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nn = dict_il_tl_nn.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_nn.json\", \"w\") as outfile:\n",
    "        json.dump(dict_nn, outfile)\n",
    "    print(\"successfully saved the dict_nn.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_nn.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Adjective Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_jj = dict_il_tl_jj.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_jj.json\", \"w\") as outfile:\n",
    "        json.dump(dict_jj, outfile)\n",
    "    print(\"successfully saved the dict_jj.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_jj.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Adverb Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rb = dict_il_tl_rb.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_rb.json\", \"w\") as outfile:\n",
    "        json.dump(dict_rb, outfile)\n",
    "    print(\"successfully saved the dict_rb.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_rb.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Conjunction Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cc = dict_il_tl_cc.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_cc.json\", \"w\") as outfile:\n",
    "        json.dump(dict_cc, outfile)\n",
    "    print(\"successfully saved the dict_cc.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_cc.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Preposition Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pr = dict_il_tl_pr.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_pr.json\", \"w\") as outfile:\n",
    "        json.dump(dict_pr, outfile)\n",
    "    print(\"successfully saved the dict_pr.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_pr.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Determiner Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dt = dict_il_tl_dt.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_dt.json\", \"w\") as outfile:\n",
    "        json.dump(dict_dt, outfile)\n",
    "    print(\"successfully saved the dict_dt.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_dt.json file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_sen_list = []\n",
    "\n",
    "temp_sen_list.append([1])\n",
    "# temp_sen_list[0].append(1)\n",
    "temp_sen_list[0][0] += 1\n",
    "print(temp_sen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_arr = ''\n",
    "\n",
    "print(len(temp_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1d54cc6ba22d92170a9f9c24d6077688435e22a85a4273e6fe4e4e6bdebfd02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
